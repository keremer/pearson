from __future__ import annotations

import json
import os
import re
import logging
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any, Dict, List, Optional, Callable
from pathlib import Path
from enum import Enum
from functools import wraps

from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from pydantic import BaseModel, Field

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ================ DECORATORS & UTILITIES ================
def require_auth(func: Callable) -> Callable:
    """Decorator to ensure authentication before method execution"""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        if not self.authenticated:
            self.authenticate()
        return func(self, *args, **kwargs)
    return wrapper


def handle_http_error(func: Callable) -> Callable:
    """Decorator to handle HTTP errors with consistent logging"""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        try:
            return func(self, *args, **kwargs)
        except HttpError as e:
            logger.error(f"‚ùå Error in {func.__name__}: {e}")
            if hasattr(self, 'service_account_email'):
                logger.info(f"üí° Tip: Ensure proper sharing with {self.service_account_email}")
            raise
    return wrapper


# ================ DATA MODELS ================
class ContentType(Enum):
    """Content type enumeration"""
    TEXT = "text"
    HTML = "html"
    PLAIN_TEXT = "plain_text"


class CourseComponent(BaseModel):
    """Base model for course components"""
    title: str
    description: Optional[str] = None
    order: int = 0


class LearningOutcome(CourseComponent):
    """Learning outcome model"""
    bloom_level: Optional[str] = None
    assessment_criteria: Optional[str] = None


class Assessment(CourseComponent):
    """Assessment model"""
    weight: float = 0.0
    due_date: Optional[str] = None
    rubric: Optional[Dict[str, Any]] = None
    submission_requirements: Optional[str] = None


class WeeklySchedule(BaseModel):
    """Weekly schedule model"""
    week_number: int
    topics: List[str] = Field(default_factory=list)
    readings: List[str] = Field(default_factory=list)
    activities: List[str] = Field(default_factory=list)
    assignments: List[str] = Field(default_factory=list)


class StructuredCourseData(BaseModel):
    """Structured course data extracted from document"""
    title: str
    description: Optional[str] = None
    learning_outcomes: List[LearningOutcome] = Field(default_factory=list)
    assessments: List[Assessment] = Field(default_factory=list)
    weekly_schedule: List[WeeklySchedule] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)


# ================ CONFIGURATION ================
class GoogleDocsConfig:
    """Configuration for Google Docs Service Account"""
    
    def __init__(self, 
                 service_account_key_path: Optional[str] = None,  # Make optional
                 target_folder_id: Optional[str] = None,
                 impersonate_user: Optional[str] = None):
        # Auto-detect JSON file in project root
        self.service_account_key_path = self._auto_find_json() if not service_account_key_path else self._resolve_path(service_account_key_path)
        self.target_folder_id = target_folder_id
        self.impersonate_user = impersonate_user
        
        if not Path(self.service_account_key_path).exists():
            raise FileNotFoundError(
                f"Service account key not found: {self.service_account_key_path}\n"
                f"Please ensure 'cgc-academic-00a28121e892.json' exists in your project root."
            )
    
    def _auto_find_json(self) -> str:
        """Automatically find the JSON key file in project root"""
        project_root = self._get_project_root()
        
        # Look for any .json file that looks like a service account key
        for file in os.listdir(project_root):
            if file.endswith('.json'):
                # Check if it looks like a service account key
                try:
                    with open(os.path.join(project_root, file), 'r') as f:
                        data = json.load(f)
                        if data.get('type') == 'service_account':
                            logger.info(f"‚úÖ Found service account key: {file}")
                            return os.path.join(project_root, file)
                except:
                    continue
        
        # If not found, check for the specific file you have
        specific_file = "cgc-academic-00a28121e892.json"
        full_path = os.path.join(project_root, specific_file)
        if os.path.exists(full_path):
            return full_path
        
        raise FileNotFoundError(
            f"No service account key found in project root: {project_root}\n"
            f"Please place your JSON key file in the project root directory."
        )
    
    def _get_project_root(self) -> str:
        """Get the absolute path to project root"""
        # Get directory of this file
        current_dir = Path(__file__).parent.absolute()
        
        # Go up until we find requirements.txt (which is in your root)
        while current_dir != current_dir.parent:
            if (current_dir / "requirements.txt").exists():
                return str(current_dir)
            current_dir = current_dir.parent
        
        # Fallback to current directory
        return os.getcwd()
    
    def _resolve_path(self, path: str) -> str:
        """Resolve relative path to absolute path from project root"""
        if os.path.isabs(path):
            return path
        
        project_root = self._get_project_root()
        full_path = os.path.join(project_root, path)
        
        # Check if exists, if not check if it's just a filename in project root
        if not os.path.exists(full_path) and not '/' in path and not '\\' in path:
            # It's just a filename, look in project root
            full_path = os.path.join(project_root, path)
        
        return full_path
    
    def _validate_config(self) -> None:
        """Validate configuration parameters"""
        if not Path(self.service_account_key_path).exists():
            raise FileNotFoundError(
                f"Service account key not found: {self.service_account_key_path}\n"
                f"Download key from: https://console.cloud.google.com/iam-admin/serviceaccounts"
            )
    
    @property
    def scopes(self) -> list:
        """Return scopes needed based on config"""
        if self.impersonate_user:
            return [
                'https://www.googleapis.com/auth/documents',
                'https://www.googleapis.com/auth/drive'
            ]
        return ['https://www.googleapis.com/auth/drive.file']
    
    def get_service_account_email(self) -> str:
        """Extract service account email from key file"""
        with open(self.service_account_key_path) as f:
            return json.load(f).get('client_email', 'Unknown')


# ================ BASE INTERFACE ================
class BaseInteropClient(ABC):
    """Base interface for document interoperability"""
    
    @abstractmethod
    def authenticate(self) -> bool:
        pass
    
    @abstractmethod
    def get_content(self, document_id: str, content_type: ContentType = ContentType.PLAIN_TEXT) -> str:
        pass
    
    @abstractmethod
    def update_content(self, document_id: str, content: str) -> bool:
        pass
    
    @abstractmethod
    def create_document(self, title: str, content: Optional[str] = None, 
                       parent_folder_id: Optional[str] = None) -> Optional[str]:
        pass
    
    @abstractmethod
    def list_documents(self, query: Optional[str] = None, 
                      folder_id: Optional[str] = None) -> List[Dict[str, Any]]:
        pass
    
    @abstractmethod
    def search_documents(self, query: str) -> List[Dict[str, Any]]:
        pass


# ================ DOCUMENT CONTENT EXTRACTORS ================
class DocumentContentExtractor:
    """Extracts different content formats from Google Docs document structure"""
    
    @staticmethod
    def extract_plain_text(document: Dict[str, Any]) -> str:
        """Extract plain text from document structure"""
        return DocumentContentExtractor._extract_text(document, join_with='')
    
    @staticmethod
    def extract_structured_text(document: Dict[str, Any]) -> str:
        """Extract structured text with paragraph markers"""
        return DocumentContentExtractor._extract_text(document, join_with='\n')
    
    @staticmethod
    def convert_to_html(document: Dict[str, Any]) -> str:
        """Convert document structure to HTML"""
        html_content = []
        
        if 'body' in document and 'content' in document['body']:
            for element in document['body']['content']:
                if 'paragraph' in element:
                    paragraph_html = []
                    for elem in element['paragraph']['elements']:
                        if 'textRun' in elem:
                            text = elem['textRun']['content']
                            style = elem['textRun'].get('textStyle', {})
                            text = DocumentContentExtractor._apply_styling(text, style)
                            paragraph_html.append(text)
                    
                    if paragraph_html:
                        html_content.append(f"<p>{''.join(paragraph_html).strip()}</p>")
        
        return '\n'.join(html_content)
    
    @staticmethod
    def _extract_text(document: Dict[str, Any], join_with: str) -> str:
        """Generic text extraction method"""
        text_parts = []
        
        if 'body' in document and 'content' in document['body']:
            for element in document['body']['content']:
                if 'paragraph' in element:
                    paragraph_text = []
                    for elem in element['paragraph']['elements']:
                        if 'textRun' in elem:
                            paragraph_text.append(elem['textRun']['content'])
                    
                    if paragraph_text:
                        text_parts.append(''.join(paragraph_text).strip())
        
        return join_with.join(text_parts)
    
    @staticmethod
    def _apply_styling(text: str, style: Dict[str, Any]) -> str:
        """Apply HTML styling to text"""
        if style.get('bold', False):
            text = f"<strong>{text}</strong>"
        if style.get('italic', False):
            text = f"<em>{text}</em>"
        if style.get('underline', False):
            text = f"<u>{text}</u>"
        return text


# ================ GOOGLE DOCS CLIENT ================
class GoogleDocsClient(BaseInteropClient):
    """Google Docs client using Service Account authentication"""
    
    def __init__(self, config: GoogleDocsConfig):
        self.config = config
        self.credentials = None
        self.docs_service = None
        self.drive_service = None
        self.authenticated = False
        self.service_account_email = config.get_service_account_email()
        self.extractor = DocumentContentExtractor()
    
    def _lazy_init_service(self, service_type: str):
        """Lazily initialize API services"""
        if service_type == 'docs' and self.docs_service is None:
            self._ensure_services_initialized()
        elif service_type == 'drive' and self.drive_service is None:
            self._ensure_services_initialized()
        
        service = self.docs_service if service_type == 'docs' else self.drive_service
        if service is None:
            raise RuntimeError(f"{service_type.capitalize()} service not initialized")
        return service
    
    def _ensure_services_initialized(self):
        """Ensure both services are initialized"""
        if not self.authenticated:
            self.authenticate()
    
    def authenticate(self) -> bool:
        """Authenticate using Service Account credentials"""
        try:
            logger.info(f"Authenticating with: {self.service_account_email}")
            
            creds = service_account.Credentials.from_service_account_file(
                self.config.service_account_key_path,
                scopes=self.config.scopes
            )
            
            if self.config.impersonate_user:
                creds = creds.with_subject(self.config.impersonate_user)
            
            self.credentials = creds
            self.docs_service = build('docs', 'v1', credentials=creds)
            self.drive_service = build('drive', 'v3', credentials=creds)
            self.authenticated = True
            
            logger.info("‚úÖ Authentication successful")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Authentication failed: {e}")
            self._reset_auth_state()
            return False
    
    def _reset_auth_state(self):
        """Reset authentication state on failure"""
        self.authenticated = False
        self.credentials = None
        self.docs_service = None
        self.drive_service = None
    
    @require_auth
    @handle_http_error
    def get_content(self, document_id: str, content_type: ContentType = ContentType.PLAIN_TEXT) -> str:
        """Get document content from Google Docs"""
        logger.info(f"Fetching document: {document_id}")
        
        docs = self._lazy_init_service('docs')
        document = docs.documents().get(documentId=document_id).execute()
        
        content_extractors = {
            ContentType.HTML: self.extractor.convert_to_html,
            ContentType.TEXT: self.extractor.extract_structured_text,
            ContentType.PLAIN_TEXT: self.extractor.extract_plain_text
        }
        
        return content_extractors[content_type](document)
    
    @require_auth
    @handle_http_error
    def update_content(self, document_id: str, content: str) -> bool:
        """Update document content in Google Docs"""
        logger.info(f"Updating document: {document_id}")
        
        docs = self._lazy_init_service('docs')
        document = docs.documents().get(documentId=document_id).execute()
        
        requests = self._prepare_update_requests(document, content)
        
        if requests:
            docs.documents().batchUpdate(
                documentId=document_id,
                body={'requests': requests}
            ).execute()
        
        logger.info(f"‚úÖ Updated document: {document_id}")
        return True
    
    def _prepare_update_requests(self, document: Dict[str, Any], content: str) -> List[Dict[str, Any]]:
        """Prepare batch update requests for document"""
        requests = []
        
        # Clear existing content
        end_index = self._get_document_end_index(document)
        if end_index > 1:
            requests.append(self._create_delete_request(end_index))
        
        # Insert new content
        if content:
            requests.append(self._create_insert_request(content))
        
        return requests
    
    def _get_document_end_index(self, document: Dict[str, Any]) -> int:
        """Get the end index of document content"""
        end_index = 1
        if 'body' in document and 'content' in document['body']:
            for element in document['body']['content']:
                if 'endIndex' in element:
                    end_index = max(end_index, element['endIndex'])
        return end_index
    
    def _create_delete_request(self, end_index: int) -> Dict[str, Any]:
        """Create delete content request"""
        return {
            'deleteContentRange': {
                'range': {
                    'startIndex': 1,
                    'endIndex': end_index - 1
                }
            }
        }
    
    def _create_insert_request(self, content: str) -> Dict[str, Any]:
        """Create insert text request"""
        return {
            'insertText': {
                'location': {'index': 1},
                'text': content
            }
        }
    
    @require_auth
    @handle_http_error
    def update_document_partial(self, document_id: str, updates: List[Dict[str, Any]]) -> bool:
        """Update specific parts of a document"""
        logger.info(f"Updating partial content: {document_id}")
        
        docs = self._lazy_init_service('docs')
        docs.documents().batchUpdate(
            documentId=document_id,
            body={'requests': updates}
        ).execute()
        
        logger.info(f"‚úÖ Updated document partially: {document_id}")
        return True
    
    @require_auth
    @handle_http_error
    def create_document(self, title: str, content: Optional[str] = None,
                       parent_folder_id: Optional[str] = None) -> Optional[str]:
        """Create a new Google Docs document"""
        logger.info(f"Creating document: {title}")
        
        drive = self._lazy_init_service('drive')
        
        file_metadata: Dict[str, Any] = {
            'name': title,
            'mimeType': 'application/vnd.google-apps.document'
        }
        
        folder_id = parent_folder_id or self.config.target_folder_id
        if folder_id:
            # Google Drive expects 'parents' to be a list of folder IDs.
            file_metadata['parents'] = [folder_id]
        
        document = drive.files().create(body=file_metadata, fields='id').execute()
        document_id = document.get('id')
        
        if content and document_id:
            self.update_content(document_id, content)
        
        logger.info(f"‚úÖ Created document: {title} (ID: {document_id})")
        return document_id
    
    @require_auth
    @handle_http_error
    def list_documents(self, query: Optional[str] = None,
                      folder_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """List Google Docs documents"""
        base_query = self._build_documents_query(query, folder_id)
        logger.info(f"Listing documents with query: {base_query}")
        
        drive = self._lazy_init_service('drive')
        results = drive.files().list(
            q=base_query,
            pageSize=100,
            fields="files(id, name, createdTime, modifiedTime, webViewLink, owners, parents)"
        ).execute()
        
        documents = results.get('files', [])
        logger.info(f"Found {len(documents)} documents")
        return documents
    
    @require_auth
    @handle_http_error
    def search_documents(self, query: str) -> List[Dict[str, Any]]:
        """Search documents by full text"""
        logger.info(f"Searching documents: {query}")
        
        search_query = (
            f"mimeType='application/vnd.google-apps.document' "
            f"and trashed=false "
            f"and fullText contains '{query}'"
        )
        
        drive = self._lazy_init_service('drive')
        results = drive.files().list(
            q=search_query,
            pageSize=100,
            fields="files(id, name, createdTime, modifiedTime, webViewLink)"
        ).execute()
        
        documents = results.get('files', [])
        logger.info(f"Found {len(documents)} documents matching search")
        return documents
    
    def _build_documents_query(self, query: Optional[str], folder_id: Optional[str]) -> str:
        """Build query for listing documents"""
        base_query = "mimeType='application/vnd.google-apps.document' and trashed=false"
        
        target_folder_id = folder_id or self.config.target_folder_id
        if target_folder_id:
            base_query += f" and '{target_folder_id}' in parents"
        
        if query:
            base_query += f" and name contains '{query}'"
        
        return base_query
    
    @require_auth
    @handle_http_error
    def get_document_metadata(self, document_id: str) -> Dict[str, Any]:
        """Get document metadata"""
        docs = self._lazy_init_service('docs')
        drive = self._lazy_init_service('drive')
        
        document = docs.documents().get(documentId=document_id).execute()
        drive_file = drive.files().get(
            fileId=document_id,
            fields='id,name,createdTime,modifiedTime,owners,webViewLink,permissions'
        ).execute()
        
        return {
            'doc_id': document_id,
            'title': document.get('title', ''),
            'drive_metadata': drive_file,
            'document_structure': {
                'sections': len([c for c in document.get('body', {}).get('content', []) 
                               if 'paragraph' in c]),
                'last_modified': drive_file.get('modifiedTime')
            }
        }
    
    @require_auth
    @handle_http_error
    def share_document(self, document_id: str, user_email: str, role: str = 'writer') -> bool:
        """Share a document with a user"""
        permission = {
            'type': 'user',
            'role': role,
            'emailAddress': user_email
        }
        
        drive = self._lazy_init_service('drive')
        drive.permissions().create(
            fileId=document_id,
            body=permission,
            sendNotificationEmail=False
        ).execute()
        
        logger.info(f"‚úÖ Shared document {document_id} with {user_email} as {role}")
        return True


# ================ DOCUMENT PARSER ================
class GoogleDocsParser:
    """Parser for extracting structured course data from Google Docs"""
    
    PATTERNS = {
        'title': r'^Course Title:?\s*(.+)$',
        'description': r'^Course Description:?\s*(.+)$',
        'learning_outcome': r'^(?:LO|Learning Outcome|Outcome)\s*(\d+)[:\.]\s*(.+?)(?:\((.+?)\))?$',
        'assessment': r'^(?:Assessment|Assignment|Exam)\s*(\d+)?[:\.]\s*(.+?)(?:\((?:Weight|Worth)?\s*([\d\.]+)%?\))?$',
        'week': r'^(?:Week|Module)\s*(\d+)[:\.]\s*(.+)$',
        'topic': r'^[-‚Ä¢*]\s*(.+)$',
        'reading': r'^Reading:?\s*(.+)$',
        'activity': r'^Activity:?\s*(.+)$',
        'assignment': r'^Assignment:?\s*(.+)$'
    }
    
    def parse_course_document(self, content: str) -> StructuredCourseData:
        """Parse document content into structured course data"""
        lines = content.split('\n')
        
        parser_state = {
            'title': "",
            'description': "",
            'learning_outcomes': [],
            'assessments': [],
            'weekly_schedule': [],
            'current_week': None
        }
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            self._process_line(line, parser_state)
        
        # Add the last week if exists
        if parser_state['current_week']:
            parser_state['weekly_schedule'].append(parser_state['current_week'])
        
        return self._build_course_data(parser_state)
    
    def _process_line(self, line: str, state: Dict[str, Any]) -> None:
        """Process a single line of document content"""
        # Try to match each pattern
        for pattern_name, pattern_func in self._get_pattern_matchers().items():
            match = pattern_func(line)
            if match:
                self._handle_pattern_match(pattern_name, match, state)
                return
        
        # If no pattern matched, treat as content for current week
        self._handle_week_content(line, state)
    
    def _get_pattern_matchers(self) -> Dict[str, Callable]:
        """Get pattern matching functions"""
        return {
            'title': lambda l: re.match(self.PATTERNS['title'], l, re.IGNORECASE),
            'description': lambda l: re.match(self.PATTERNS['description'], l, re.IGNORECASE),
            'learning_outcome': lambda l: re.match(self.PATTERNS['learning_outcome'], l, re.IGNORECASE),
            'assessment': lambda l: re.match(self.PATTERNS['assessment'], l, re.IGNORECASE),
            'week': lambda l: re.match(self.PATTERNS['week'], l, re.IGNORECASE)
        }
    
    def _handle_pattern_match(self, pattern_name: str, match: re.Match, state: Dict[str, Any]) -> None:
        """Handle matched pattern"""
        handlers = {
            'title': lambda: self._handle_title(match, state),
            'description': lambda: self._handle_description(match, state),
            'learning_outcome': lambda: self._handle_learning_outcome(match, state),
            'assessment': lambda: self._handle_assessment(match, state),
            'week': lambda: self._handle_week(match, state)
        }
        
        if pattern_name in handlers:
            handlers[pattern_name]()
    
    def _handle_title(self, match: re.Match, state: Dict[str, Any]) -> None:
        """Handle title pattern match"""
        if not state['title']:
            state['title'] = match.group(1).strip()
    
    def _handle_description(self, match: re.Match, state: Dict[str, Any]) -> None:
        """Handle description pattern match"""
        if not state['description']:
            state['description'] = match.group(1).strip()
    
    def _handle_learning_outcome(self, match: re.Match, state: Dict[str, Any]) -> None:
        """Handle learning outcome pattern match"""
        outcome = LearningOutcome(
            title=match.group(2).strip(),
            description=match.group(3).strip() if match.group(3) else None,
            order=int(match.group(1)) if match.group(1) else len(state['learning_outcomes']) + 1
        )
        state['learning_outcomes'].append(outcome)
    
    def _handle_assessment(self, match: re.Match, state: Dict[str, Any]) -> None:
        """Handle assessment pattern match"""
        assessment = Assessment(
            title=match.group(2).strip(),
            weight=float(match.group(3)) if match.group(3) else 0.0,
            order=int(match.group(1)) if match.group(1) else len(state['assessments']) + 1
        )
        state['assessments'].append(assessment)
    
    def _handle_week(self, match: re.Match, state: Dict[str, Any]) -> None:
        """Handle week pattern match"""
        if state['current_week']:
            state['weekly_schedule'].append(state['current_week'])
        
        state['current_week'] = WeeklySchedule(
            week_number=int(match.group(1)),
            topics=[]
        )
        
        if match.group(2):
            state['current_week'].topics.append(match.group(2).strip())
    
    def _handle_week_content(self, line: str, state: Dict[str, Any]) -> None:
        """Handle content within a week"""
        if not state['current_week']:
            return
        
        content_handlers = {
            'topic': (r'^[-‚Ä¢*]\s*(.+)$', lambda m: state['current_week'].topics.append(m.group(1).strip())),
            'reading': (r'^Reading:?\s*(.+)$', lambda m: state['current_week'].readings.append(m.group(1).strip())),
            'activity': (r'^Activity:?\s*(.+)$', lambda m: state['current_week'].activities.append(m.group(1).strip())),
            'assignment': (r'^Assignment:?\s*(.+)$', lambda m: state['current_week'].assignments.append(m.group(1).strip()))
        }
        
        for pattern_name, (pattern, handler) in content_handlers.items():
            match = re.match(pattern, line, re.IGNORECASE)
            if match:
                handler(match)
                return
    
    def _build_course_data(self, state: Dict[str, Any]) -> StructuredCourseData:
        """Build StructuredCourseData from parser state"""
        metadata = {
            'parsed_at': datetime.utcnow().isoformat(),
            'total_learning_outcomes': len(state['learning_outcomes']),
            'total_assessments': len(state['assessments']),
            'total_weeks': len(state['weekly_schedule'])
        }
        
        return StructuredCourseData(
            title=state['title'],
            description=state['description'],
            learning_outcomes=state['learning_outcomes'],
            assessments=state['assessments'],
            weekly_schedule=state['weekly_schedule'],
            metadata=metadata
        )


# ================ MANAGER ================
class GoogleDocsManager:
    """Manager for Google Docs operations with course data"""
    
    def __init__(self, client: GoogleDocsClient, parser: Optional[GoogleDocsParser] = None):
        self.client = client
        self.parser = parser or GoogleDocsParser()
        
        if not client.authenticated:
            client.authenticate()
    
    def fetch_and_parse_course(self, document_id: str) -> StructuredCourseData:
        """Fetch and parse course document"""
        content = self.client.get_content(document_id, ContentType.PLAIN_TEXT)
        course_data = self.parser.parse_course_document(content)
        
        metadata = self.client.get_document_metadata(document_id)
        course_data.metadata.update({
            'document_id': document_id,
            'document_title': metadata.get('title', ''),
            'last_modified': metadata.get('drive_metadata', {}).get('modifiedTime')
        })
        
        logger.info(f"‚úÖ Parsed course: {course_data.title}")
        return course_data
    
    def create_course_document(self, course_data: StructuredCourseData, 
                             folder_id: Optional[str] = None) -> Optional[str]:
        """Create a new course document"""
        content = self._format_course_to_document(course_data)
        return self.client.create_document(
            title=course_data.title,
            content=content,
            parent_folder_id=folder_id
        )
    
    def sync_course_data(self, document_id: str, 
                        db_course_data: StructuredCourseData) -> StructuredCourseData:
        """Sync document content with database"""
        document_content = self.client.get_content(document_id, ContentType.PLAIN_TEXT)
        document_data = self.parser.parse_course_document(document_content)
        
        merged_data = self._merge_course_data(document_data, db_course_data)
        
        if document_data != merged_data:
            updated_content = self._format_course_to_document(merged_data)
            self.client.update_content(document_id, updated_content)
            logger.info(f"‚úÖ Updated document with merged data")
        
        return merged_data
    
    def update_course_document(self, document_id: str, 
                             course_data: StructuredCourseData) -> bool:
        """Update course document with new data"""
        content = self._format_course_to_document(course_data)
        return self.client.update_content(document_id, content)
    
    def search_courses(self, query: str) -> List[Dict[str, Any]]:
        """Search for course documents"""
        return self.client.search_documents(query)
    
    def list_course_documents(self, folder_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """List all course documents"""
        return self.client.list_documents(query="course", folder_id=folder_id)
    
    def _format_course_to_document(self, course_data: StructuredCourseData) -> str:
        """Format structured course data to document text"""
        sections = []
        
        sections.append(f"Course Title: {course_data.title}\n")
        
        if course_data.description:
            sections.append(f"Course Description: {course_data.description}\n")
        
        if course_data.learning_outcomes:
            sections.append(self._format_section(
                "Learning Outcomes:",
                course_data.learning_outcomes,
                lambda lo: f"  {lo.order}. {lo.title}" + (f" ({lo.description})" if lo.description else "")
            ))
        
        if course_data.assessments:
            sections.append(self._format_section(
                "Assessments:",
                course_data.assessments,
                lambda a: f"  {a.order}. {a.title}" + (f" (Weight: {a.weight}%)" if a.weight > 0 else "") +
                         (f"\n     Description: {a.description}" if a.description else "")
            ))
        
        if course_data.weekly_schedule:
            sections.append(self._format_weekly_schedule(course_data.weekly_schedule))
        
        return '\n'.join(sections)
    
    def _format_section(self, title: str, items: List, formatter: Callable) -> str:
        """Format a section with items"""
        lines = [title]
        for item in sorted(items, key=lambda x: x.order):
            lines.append(formatter(item))
        lines.append("")
        return '\n'.join(lines)
    
    def _format_weekly_schedule(self, weekly_schedule: List[WeeklySchedule]) -> str:
        """Format weekly schedule section"""
        lines = ["Weekly Schedule:"]
        
        for week in sorted(weekly_schedule, key=lambda x: x.week_number):
            lines.append(f"Week {week.week_number}: {week.topics[0] if week.topics else 'TBD'}")
            
            for topic in week.topics[1:]:
                lines.append(f"  ‚Ä¢ {topic}")
            
            for category, items in [
                ("Readings", week.readings),
                ("Activities", week.activities),
                ("Assignments", week.assignments)
            ]:
                if items:
                    lines.append(f"  {category}:")
                    for item in items:
                        lines.append(f"    ‚Ä¢ {item}")
            
            lines.append("")
        
        return '\n'.join(lines)
    
    def _merge_course_data(self, doc_data: StructuredCourseData, 
                          db_data: StructuredCourseData) -> StructuredCourseData:
        """Merge document data with database data"""
        merged_metadata = {
            **db_data.metadata,
            **doc_data.metadata,
            'merged_at': datetime.utcnow().isoformat(),
            'source': 'merged'
        }
        
        return StructuredCourseData(
            title=doc_data.title or db_data.title,
            description=doc_data.description or db_data.description,
            learning_outcomes=doc_data.learning_outcomes or db_data.learning_outcomes,
            assessments=doc_data.assessments or db_data.assessments,
            weekly_schedule=doc_data.weekly_schedule or db_data.weekly_schedule,
            metadata=merged_metadata
        )


# ================ MAIN ENTRY POINT ================
if __name__ == "__main__":
    config = GoogleDocsConfig(
        service_account_key_path="cgc-academic-00a28121e892.json",
        target_folder_id="0B5TNPykApXfkcWY3U0ROc0xZc3c"
    )
    
    client = GoogleDocsClient(config)
    parser = GoogleDocsParser()
    manager = GoogleDocsManager(client, parser)
    
    try:
        print("\nüìÑ Testing Google Docs Integration:")
        
        # List documents
        documents = client.list_documents()
        if documents:
            for doc in documents[:3]:
                print(f"‚Ä¢ {doc['name']} (ID: {doc['id']})")
            
            # Parse first document
            if documents:
                doc_id = documents[0]['id']
                course_data = manager.fetch_and_parse_course(doc_id)
                print(f"\n‚úÖ Parsed: {course_data.title}")
        else:
            print("‚ö†Ô∏è  No documents found - share documents with service account")
            
    except Exception as e:
        print(f"\n‚ùå Error: {e}")